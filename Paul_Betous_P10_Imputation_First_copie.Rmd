---
title: "R Notebook"
output: html_notebook
---

```{r}
df_global <- read.csv("billets.csv", sep = ";")
df_production <- read.csv("billets_production.csv")
summary(df_global)
```

```{r}
# Imputation des valeurs manquantes par regression linéaire
library(mice)
# Visualisation des données manquantes :
md.pattern(df_global)
imputed <- mice(df_global, meth = "norm")
print(imputed$imp$margin_low)
```

```{r}
imputed_data <- mice::complete(imputed)
summary(imputed_data)
reg_MarginLow <- lm(margin_low ~ diagonal + height_left + height_right + margin_up + length, data = imputed_data)
summary(reg_MarginLow)
shapiro.test(reg_MarginLow$residuals)
library(lmtest)
bptest(reg_MarginLow)
plot(reg_MarginLow$residuals)
```

#Selon le test de Shapiro-Wilk la distribution des résidus ne suit pas une loi normale, selon le test de Breush Pagan il n'y a pas hétéroscédasticité des résidus

```{r}
#Distribution des billets
barplot(table(imputed_data$is_genuine), col = c("#00AFBB", "#E7B800"))
```
```{r}
sapply(imputed_data, sd)

```
```{r}
# Vrais Billets
summary(imputed_data[imputed_data$is_genuine == "True", ])
sapply(imputed_data[imputed_data$is_genuine == "True",], sd)

```
```{r}
# Faux Billets
summary(imputed_data[imputed_data$is_genuine == "False", ])
sapply(imputed_data[imputed_data$is_genuine == "False",], sd)

```




```{r}
library(ggplot2)
theme_set(
  theme_classic() + 
    theme(legend.position = "top")
  )

# histogrammes par categorie de billet
ggplot(imputed_data, aes(x = diagonal)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(imputed_data, aes(x = height_left)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(imputed_data, aes(x = height_right)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(imputed_data, aes(x = margin_low)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(imputed_data, aes(x = margin_up)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(imputed_data, aes(x = length)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))

```




```{r}
# boxplot par categorie de billet
boxplot(diagonal ~ is_genuine, data = imputed_data, col = c("#00AFBB", "#E7B800"))
boxplot(height_left ~ is_genuine, data = imputed_data, col = c("#00AFBB", "#E7B800"))
boxplot(height_right ~ is_genuine, data = imputed_data, col = c("#00AFBB", "#E7B800"))
boxplot(margin_low ~ is_genuine, data = imputed_data, col = c("#00AFBB", "#E7B800"))
boxplot(margin_up ~ is_genuine, data = imputed_data, col = c("#00AFBB", "#E7B800"))
boxplot(length ~ is_genuine, data = imputed_data, col = c("#00AFBB", "#E7B800"))
```

```{r}
library(caret)
```

```{r}
training.idx <- createDataPartition(imputed_data$is_genuine, p=0.7, list = FALSE) 

training <- imputed_data[training.idx,] # creation du jeu de données "train" 
testing <- imputed_data[-training.idx,] # creation du jeu de données "test"

dim(training)
dim(testing)


round(table(training$is_genuine)/nrow(training),2)
round(table(testing$is_genuine)/nrow(testing),2)


```

# ALGORITHMES SANS RESAMPLING

```{r}
# Clustering par Kmeans 
#centrage réduction des données

training_scale <- scale(training[2:7],center=T,scale=T)

#(1)évaluer la proportion d'inerti:e expliquée
inertie.expl <- rep(0,times=10)
for (k in 2:10){
  clus <- kmeans(training_scale,centers=k,nstart=5)
  inertie.expl[k] <- clus$betweenss/clus$totss
}
#graphique
plot(1:10,inertie.expl,type="b",xlab="Nb. de groupes",ylab="% inertie expliquée")
#(2) indice de Calinski Harabasz - utilisation du package fpc
library(fpc)
#évaluation des solutions
sol.kmeans <- kmeansruns(training_scale,krange=2:10,criterion="ch")
#graphique
plot(1:10,sol.kmeans$crit,type="b",xlab="Nb. de groupes",ylab="Silhouette")
```

```{r}
# Création et assignation des clusters
library(flexclust)
#set.seed(2550)
#clust <- cclust(training_scale, k=2)
#save(clust, file = "clust.Rdata", ascii = TRUE)
load("clust.RData")
print(clust)
centroid <- clust@centers
centroid
clust@cluster
```
701 Billets ont été assignés au cluster 1 (Vrai) et 349 au cluster 2 (Faux)

```{r}
training_scale <- data.frame(training_scale,clust@cluster, training$is_genuine)
training_scale
```

```{r}
ggplot(training_scale, aes(clust.cluster, margin_up, col = training.is_genuine)) + geom_point(size = 2, alpha = 0.8, position = "jitter") + scale_color_manual(values=c("#00AFBB", "#E7B800"))
```

```{r}
testing_scale <- scale(testing[2:7])
#clust_predict <- predict(clust, testing_scale)
#if(any(clust_predict == 1)) clust_predict <- ifelse(clust_predict == 1, "True", "False")
#save(clust_predict, file = "clust_predict.RData", ascii = TRUE)

```


```{r}
load("clust_predict.RData")
testing_scale <- data.frame(testing_scale,clust_predict, testing$is_genuine)
```

```{r}
ggplot(testing_scale, aes(clust_predict, margin_up, col = testing.is_genuine)) + geom_point(size = 2, alpha = 0.8, position = "jitter") + scale_color_manual(values=c("#00AFBB", "#E7B800"))
```



```{r}
library(yardstick)
testing_scale
#mat_kmeans <- conf_mat(testing_scale, testing.is_genuine, clust_predict)
#save(mat_kmeans, file = "mat_kmeans.RData", ascii = TRUE)
load("mat_kmeans.RData")
summary(mat_kmeans)
#roc_curve(testing_scale, as.factor(testing.is_genuine), 7)
#autoplot(roc_curve(testing_scale, as.factor(testing.is_genuine), 7))
autoplot(mat_kmeans, type="heatmap") + scale_fill_distiller(palette = "YlOrRd") + ggtitle('Matrice de confusion: Kmeans sans resampling')
mat_kmeans

```


```{r}
#regresion logistique
#set.seed(2550)
#logit.fit <- train(is_genuine ~ diagonal + height_left + height_right + margin_low + margin_up + length, data = training,method="glm")
#save(logit.fit, file = "logit.fit.RData", ascii = TRUE)
load("logit.fit.RData")
#testing$clust_predict <- predict(logit.fit,newdata=testing)
#save(testing, file = "testing.RData", ascii = TRUE)
load("testing.RData")

```

```{r}
#score (probabilité) de chaque individu
library(pROC)
#score <- predict(logit.fit, testing, type="prob")[,"False"] #probabilité qu'un billet soit faux
#save(score, file = "score.RData", ascii = TRUE)
load("score.RData")
print(quantile(score))
testing$proba <- score
print(testing[order(testing$proba),][testing$clust_predict == "False",])
#objet roc
roc_obj <- roc(testing$is_genuine=="False",score)
summary(roc_obj)
#plot de l'objet roc
plot(1-roc_obj$specificities,roc_obj$sensitivities,type="l")
abline(0,1)
print(roc_obj$auc)

```

```{r}

#mat <- confusionMatrix(data=pred,reference=as.factor(testing$is_genuine))
#mat
#mat_regLog <- conf_mat(testing, is_genuine, clust_predict)
#save(mat_regLog, file = "mat_regLog.RData", ascii = TRUE)
load("mat_regLog.RData")
summary(mat_regLog)
autoplot(mat_regLog, type="heatmap")  + scale_fill_distiller(palette = "YlOrRd") + ggtitle('Matrice de confusion: Régression Logistique sans resampling')
mat
```

```{r}
#prediction
testing$clust_predict
```

# BILLETS PRODUCTION

```{r}
is_genuine <- predict(logit.fit,newdata=df_production)
df_production <- cbind(df_production, is_genuine)
df_production
```



# ALGORITHME AVEC OVERSAMPLING DES FAUX BILLETS

```{r}
print(table(training$is_genuine))
set.seed(2550)
new <- upSample(training[2:7][,-7], y = as.factor(training$is_genuine), yname = "is_genuine")
print(table(new$is_genuine))

```


```{r}
new
```

```{r}
ggplot(new[new$is_genuine == "False",],aes(x=diagonal)) + geom_histogram(col="blue", fill= "blue", bins=30) + geom_histogram(data=training[training$is_genuine == "False",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après oversampling")
ggplot(new[new$is_genuine == "False",],aes(x=length)) + geom_histogram(col="blue", fill= "blue", bins=30) + geom_histogram(data=training[training$is_genuine == "False",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après oversampling")
ggplot(new[new$is_genuine == "False",],aes(x=height_right)) + geom_histogram(col="blue", fill= "blue", bins=30) + geom_histogram(data=training[training$is_genuine == "False",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après oversampling")
ggplot(new[new$is_genuine == "False",],aes(x=height_left)) + geom_histogram(col="blue", fill= "blue", bins=30) + geom_histogram(data=training[training$is_genuine == "False",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après oversampling")
ggplot(new[new$is_genuine == "False",],aes(x=margin_up)) + geom_histogram(col="blue", fill= "blue", bins=30) + geom_histogram(data=training[training$is_genuine == "False",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après oversampling")
ggplot(new[new$is_genuine == "False",],aes(x=margin_low)) + geom_histogram(col="blue", fill= "blue", bins=30) + geom_histogram(data=training[training$is_genuine == "False",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après oversampling")
```



```{r}
UpTraining <- new
summary(UpTraining)
sapply(UpTraining[,1:6], sd)
print(table(UpTraining$is_genuine))
```

```{r}
# histogrammes par categorie de billet, après OVERSAMPLING
ggplot(UpTraining, aes(x = diagonal)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(UpTraining, aes(x = height_left)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(UpTraining, aes(x = height_right)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(UpTraining, aes(x = margin_low)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(UpTraining, aes(x = margin_up)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(UpTraining, aes(x = length)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))

```


```{r}
# Clustering par Kmeans 
#centrage réduction des données

UpTraining_scale <- scale(UpTraining[1:6],center=T,scale=T)

#(1)évaluer la proportion d'inerti:e expliquée
inertie.expl <- rep(0,times=10)
for (k in 2:10){
  clus <- kmeans(UpTraining_scale,centers=k,nstart=5)
  inertie.expl[k] <- clus$betweenss/clus$totss
}
#graphique
plot(1:10,inertie.expl,type="b",xlab="Nb. de groupes",ylab="% inertie expliquée")

#évaluation des solutions
sol.kmeans <- kmeansruns(UpTraining_scale,krange=2:10,criterion="ch")
#graphique
plot(1:10,sol.kmeans$crit,type="b",xlab="Nb. de groupes",ylab="Silhouette")
```

```{r}
# Création et assignation des clusters

#set.seed(2550)
#clust_over <- cclust(UpTraining_scale, k=2)
#save(clust_over, file = "clust_over.RData", ascii = TRUE)
load("clust_over.RData")
print(clust_over)
summary(clust_over)
centroid_over <- clust_over@centers
centroid_over
clust_over@centers
```
690 Billets ont été assignés au cluster 1 (Faux) et 710 au cluster 2 (Vrai)


```{r}
UpTraining_scale <- data.frame(UpTraining_scale,clust_over@cluster, UpTraining$is_genuine)
ggplot(UpTraining_scale, aes(clust_over.cluster, margin_up, col = UpTraining.is_genuine)) + geom_point(size = 2, alpha = 0.8, position = "jitter") + scale_color_manual(values=c("#00AFBB", "#E7B800"))
```

```{r}
testing_scale <- scale(testing[2:7])
#clust_over_predict <- predict(clust_over, testing_scale)
#if(any(clust_over_predict == 2)) clust_over_predict <- ifelse(clust_over_predict == 2, "True", "False")
#save(clust_over_predict, file = "clust_over_predict.RData")
load("clust_over_predict.RData")
testing_scale <- data.frame(testing_scale,clust_over_predict,testing$is_genuine)
testing_scale
```


```{r}
ggplot(testing_scale, aes(clust_over_predict, margin_up, col = testing.is_genuine)) + geom_point(size = 2, alpha = 0.8, position = "jitter") + scale_color_manual(values=c("#00AFBB", "#E7B800"))
```

```{r}

#mat_kmeans_over <- conf_mat(testing_scale, testing.is_genuine, clust_over_predict)
#save(mat_kmeans_over, file = "mat_kmeans_over.RData", ascii = TRUE)
load("mat_kmeans_over.RData")
summary(mat_kmeans_over)
autoplot(mat_kmeans_over, type="heatmap") + scale_fill_distiller(palette = "YlOrRd") + ggtitle('Matrice de confusion: Kmeans avec oversampling')
```

```{r}
#regresion logistique
#set.seed(2550)
#logit_over.fit <- train(is_genuine ~ diagonal + height_left + height_right + margin_low + margin_up + length, data = UpTraining,method="glm")
#logit_over.fit
#save(logit_over.fit, file = "logit_over.RData", ascii = TRUE)
load("logit_over.RData")
#pred <- predict(logit.fit,newdata=testing)
#pred
#testing_over = subset(testing, select = -clust_predict)
#testing_over$clust_over_predict <- predict(logit_over.fit,newdata=testing_over)
#save(testing_over, file = "testing_over.Rdata", ascii = TRUE)
load("testing_over.RData")
#mat <- confusionMatrix(data=pred,reference=as.factor(testing$is_genuine))
#mat
testing_over
#mat_regLog_over <- conf_mat(testing_over, is_genuine, clust_over_predict)
#save(mat_regLog_over, file = "mat_regLog_over.RData", ascii = TRUE)
load("mat_regLog_over.RData")
summary(mat_regLog_over)
autoplot(mat_regLog_over, type="heatmap") + scale_fill_distiller(palette = "YlOrRd") + ggtitle('Matrice de confusion: Regression Logistique avec oversampling')
```
```{r}

testing_over
#score (probabilité) de chaque individu

#score_over <- predict(logit_over.fit, testing_over, type="prob")[,"False"]
#save(score_over, file = "score_over.RData", ascii = TRUE)
load("score_over.RData")
testing_over$proba <- score_over
print(testing_over[order(testing_over$proba),][testing_over$clust_over_predict == "False",])
#objet roc
roc_obj_over <- roc(testing_over$is_genuine=="False",score_over)
roc_obj_over
#plot de l'objet roc
plot(1-roc_obj_over$specificities,roc_obj_over$sensitivities,type="l")
abline(0,1)
print(roc_obj_over$auc)
```

# BILLETS PRODUCTION

```{r}
is_genuine <- predict(logit_over.fit,newdata=df_production)
df_production <- cbind(df_production, is_genuine)
df_production
```

# ALGORITHME AVEC UNDERSAMPLING DES FAUX BILLETS

```{r}

print(table(training$is_genuine))

library(smotefamily)
set.seed(2550)
new <- downSample(training[2:7][,-8], y = as.factor(training$is_genuine), yname = "is_genuine")
print(table(new$is_genuine))

```


```{r}
ggplot(new[new$is_genuine == "True",],aes(x=diagonal)) + geom_histogram(data=training[training$is_genuine == "True",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après undersampling") + geom_histogram(col="blue", fill= "blue", bins=30)
ggplot(new[new$is_genuine == "True",],aes(x=length)) + geom_histogram(data=training[training$is_genuine == "True",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après undersampling") + geom_histogram(col="blue", fill= "blue", bins=30)
ggplot(new[new$is_genuine == "True",],aes(x=height_right)) + geom_histogram(data=training[training$is_genuine == "True",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après undersampling") + geom_histogram(col="blue", fill= "blue", bins=30)
ggplot(new[new$is_genuine == "True",],aes(x=height_left)) + geom_histogram(data=training[training$is_genuine == "True",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après undersampling") + geom_histogram(col="blue", fill= "blue", bins=30)
ggplot(new[new$is_genuine == "True",],aes(x=margin_up)) + geom_histogram(data=training[training$is_genuine == "True",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après undersampling") + geom_histogram(col="blue", fill= "blue", bins=30)
ggplot(new[new$is_genuine == "True",],aes(x=margin_low)) + geom_histogram(data=training[training$is_genuine == "True",],col="red", fill = "red", bins=30) + labs(title = "Distribution avant/après undersampling") + geom_histogram(col="blue", fill= "blue", bins=30)
```


```{r}
DownTraining <- new
summary(DownTraining)
sapply(DownTraining[,1:6], sd)
print(table(DownTraining$is_genuine))
```

```{r}
# histogrammes par categorie de billet, après UNDERSAMPLING
ggplot(DownTraining, aes(x = diagonal)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(DownTraining, aes(x = height_left)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(DownTraining, aes(x = height_right)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(DownTraining, aes(x = margin_low)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(DownTraining, aes(x = margin_up)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))
ggplot(DownTraining, aes(x = length)) +
  geom_histogram(aes(color = is_genuine, fill = is_genuine), 
                position = "identity", bins = 30, alpha = 0.4) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800"))

```

```{r}
# Clustering par Kmeans 
#centrage réduction des données

DownTraining_scale <- scale(DownTraining[1:6],center=T,scale=T)

#(1)évaluer la proportion d'inerti:e expliquée
inertie.expl <- rep(0,times=10)
for (k in 2:10){
  clus <- kmeans(DownTraining_scale,centers=k,nstart=5)
  inertie.expl[k] <- clus$betweenss/clus$totss
}
#graphique
plot(1:10,inertie.expl,type="b",xlab="Nb. de groupes",ylab="% inertie expliquée")

#évaluation des solutions
sol.kmeans <- kmeansruns(DownTraining_scale,krange=2:10,criterion="ch")
#graphique
plot(1:10,sol.kmeans$crit,type="b",xlab="Nb. de groupes",ylab="Silhouette")
```

```{r}
# Création et assignation des clusters
#library(flexclust)
#set.seed(2550)
#clust_under <- cclust(DownTraining_scale, k=2)
#save(clust_under, file = "clust_under.RData", ascii = TRUE)
load("clust_under.RData")
print(clust_under)
summary(clust_under)
centroid_under <- clust_under@centers
centroid_under
clust_under@centers
```

354 billets ont été assignés au cluster 1 (Vrai) et 346 au cluster 2 (Faux)


```{r}
DownTraining_scale <- data.frame(DownTraining_scale,clust_under@cluster, DownTraining$is_genuine)
ggplot(DownTraining_scale, aes(clust_under.cluster, margin_up, col = DownTraining.is_genuine)) + geom_point(size = 2, alpha = 0.8, position = "jitter") + scale_color_manual(values=c("#00AFBB", "#E7B800"))
```

```{r}
testing_scale <- scale(testing[2:7])
testing_scale
#clust_under_predict <- predict(clust_under, testing_scale)
#if(any(clust_under_predict == 1)) clust_under_predict <- ifelse(clust_under_predict == 1, "True", "False")
#save(clust_under_predict, file = "clust_under_predict.RData", ascii = TRUE)
load("clust_under_predict.RData")
testing_scale <- data.frame(testing_scale,clust_under_predict, testing$is_genuine)
testing_scale
```

```{r}

ggplot(testing_scale, aes(clust_under_predict, margin_up, col = testing.is_genuine)) + geom_point(size = 2, alpha = 0.8, position = "jitter") + scale_color_manual(values=c("#00AFBB", "#E7B800"))
```

```{r}
#mat_kmeans_under <- conf_mat(testing_scale, testing.is_genuine, clust_under_predict)
#save(mat_kmeans_under, file = "mat_kmeans_under.RData", ascii = TRUE)
load("mat_kmeans_under.RData")
summary(mat_kmeans_under)
autoplot(mat_kmeans_under, type="heatmap") + scale_fill_distiller(palette = "YlOrRd") + ggtitle('Matrice de confusion: Kmeans avec undersampling')
```

```{r}
#regresion logistique
#set.seed(2550)
#logit_under.fit <- train(is_genuine ~ diagonal + height_left + height_right + margin_low + margin_up + length, data = DownTraining,method="glm")
#logit_under.fit
#save(logit_under.fit, file = "logit_under.RData", ascii = TRUE)
load("logit_under.Rdata")
#testing_under = subset(testing, select = -clust_predict)
#testing_under$clust_under_predict <- predict(logit_under.fit,newdata=testing_under)
#save(testing_under, file = "testing_under.RData", ascii = TRUE)
load("testing_under.RData")
```

```{r}
#str(pred)
#str(testing$is_genuine)
#mat <- confusionMatrix(data=pred,reference=as.factor(testing$is_genuine))
#mat
#mat_regLog_under <- conf_mat(testing_under, is_genuine, clust_under_predict)
#save(mat_regLog_under, file = "mat_regLog_under.RData")
load("mat_regLog_under.RData")
summary(mat_regLog_under)
autoplot(mat_regLog_under, type="heatmap") + scale_fill_distiller(palette = "YlOrRd") + ggtitle('Matrice de confusion: Regression Logistique avec undersampling')
```

```{r}
#score (probabilité) de chaque individu

#score_under <- predict(logit_under.fit, testing_under, type="prob")[,"False"]
#save(score_under, file = "score_under.RData", ascii = TRUE)
load("score_under.RData")
score_under
testing_under$proba <- score_under
testing_under
print(testing_under[order(testing_under$proba),][testing_under$clust_under_predict == "False",])
#objet roc
roc_obj_under <- roc(testing_under$is_genuine=="False",score_under)
summary(roc_obj_under)
#plot de l'objet roc
plot(1-roc_obj_under$specificities,roc_obj_under$sensitivities,type="l")
abline(0,1)
print(roc_obj_under$auc)
```

# BILLETS PRODUCTION

```{r}
is_genuine <- predict(logit_under.fit,newdata=df_production)
df_production <- cbind(df_production, is_genuine)
df_production
```

```{r}
VraiFaux <- function(df)
{val<-predict(logit.fit, newdata=df)
return(print(val))}
```

```{r}
test <- read.csv("billets_test.csv", sep = ",")
VraiFaux(test)
```
